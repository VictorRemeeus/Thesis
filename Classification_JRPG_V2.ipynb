{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter searching: https://www.projectpro.io/recipes/find-optimal-parameters-using-gridsearchcv \\\n",
    "Renaming the last column: https://stackoverflow.com/questions/56479835/rename-only-the-last-column-in-pandas-dataframe-accounting-for-duplicate-header"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in dataset normal, STM and BerTopic\n",
    "df = pandas.read_csv(\"G:\\\\Master\\\\Block 3\\\\Thesis\\\\JRPG\\\\JRPG_final.csv\")\n",
    "df_STM = pandas.read_csv(\"G:\\\\Master\\\\Block 3\\\\Thesis\\\\JRPG\\\\features_JRPG_STM.csv\")\n",
    "df_Bert = pandas.read_csv(\"G:\\\\Master\\\\Block 3\\\\Thesis\\\\JRPG\\\\features_JRPG_Bert_reduction.csv\")\n",
    "df_STM_selected = pandas.read_csv(\"G:\\\\Master\\\\Block 3\\\\Thesis\\\\JRPG\\\\JRPG_featured_selected_STM.csv\")\n",
    "df_Bert_selected = pandas.read_csv(\"G:\\\\Master\\\\Block 3\\\\Thesis\\\\JRPG\\\\JRPG_featured_selected_Bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_STM.columns = [*df_STM.columns[:-1], 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V152</th>\n",
       "      <th>V153</th>\n",
       "      <th>V154</th>\n",
       "      <th>V155</th>\n",
       "      <th>V156</th>\n",
       "      <th>V157</th>\n",
       "      <th>V158</th>\n",
       "      <th>V159</th>\n",
       "      <th>V160</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.033125</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.018034</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.013706</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.013473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22016</th>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.018792</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22017</th>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22018</th>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.021311</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.034076</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22019</th>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.064734</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22020</th>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.008917</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22021 rows × 161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0      0.000946  0.004229  0.001029  0.002597  0.001067  0.001159  0.001489   \n",
       "1      0.000601  0.002419  0.001877  0.013706  0.000828  0.004858  0.000815   \n",
       "2      0.000274  0.001343  0.000217  0.001005  0.000304  0.000291  0.000513   \n",
       "3      0.000574  0.006220  0.000623  0.001124  0.000791  0.000435  0.001030   \n",
       "4      0.002103  0.006105  0.001893  0.001594  0.001879  0.001030  0.005828   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "22016  0.000609  0.002622  0.000624  0.018792  0.000762  0.000707  0.000686   \n",
       "22017  0.001277  0.007287  0.003990  0.001820  0.002148  0.001136  0.002438   \n",
       "22018  0.002292  0.004106  0.021311  0.001558  0.001766  0.000485  0.002597   \n",
       "22019  0.001918  0.005234  0.002407  0.064734  0.004365  0.001380  0.002878   \n",
       "22020  0.000851  0.003010  0.001833  0.008917  0.001172  0.000779  0.001236   \n",
       "\n",
       "             V8        V9       V10  ...      V152      V153      V154  \\\n",
       "0      0.001309  0.033125  0.002814  ...  0.001329  0.001360  0.000579   \n",
       "1      0.001497  0.001721  0.001383  ...  0.000314  0.001147  0.000138   \n",
       "2      0.000618  0.018509  0.001293  ...  0.000406  0.000828  0.000313   \n",
       "3      0.001222  0.003205  0.005092  ...  0.001164  0.001214  0.000259   \n",
       "4      0.001948  0.003762  0.013473  ...  0.002071  0.002566  0.000289   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "22016  0.000967  0.005292  0.002555  ...  0.000439  0.000826  0.000386   \n",
       "22017  0.002418  0.000971  0.003876  ...  0.001132  0.001727  0.000334   \n",
       "22018  0.002586  0.000700  0.006279  ...  0.000289  0.002211  0.000497   \n",
       "22019  0.001677  0.003644  0.003618  ...  0.000506  0.002391  0.001036   \n",
       "22020  0.001382  0.001119  0.001367  ...  0.000480  0.001719  0.000256   \n",
       "\n",
       "           V155      V156      V157      V158      V159      V160  sentiment  \n",
       "0      0.000417  0.002206  0.000220  0.018034  0.001644  0.001930          0  \n",
       "1      0.000306  0.000627  0.000383  0.002241  0.000308  0.001134          1  \n",
       "2      0.000488  0.002502  0.000056  0.001123  0.005047  0.000774          0  \n",
       "3      0.000569  0.002931  0.000724  0.000880  0.001221  0.001472          0  \n",
       "4      0.000398  0.001988  0.000751  0.002018  0.001873  0.002254          0  \n",
       "...         ...       ...       ...       ...       ...       ...        ...  \n",
       "22016  0.000374  0.001724  0.000448  0.001086  0.000960  0.001230          0  \n",
       "22017  0.000820  0.000915  0.000909  0.000770  0.002556  0.002130          0  \n",
       "22018  0.002162  0.034076  0.000394  0.001061  0.003629  0.001872          0  \n",
       "22019  0.001060  0.001988  0.000870  0.002659  0.032034  0.002224          0  \n",
       "22020  0.000335  0.001047  0.000749  0.000945  0.001902  0.001521          1  \n",
       "\n",
       "[22021 rows x 161 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_STM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V151</th>\n",
       "      <th>V152</th>\n",
       "      <th>V153</th>\n",
       "      <th>V154</th>\n",
       "      <th>V156</th>\n",
       "      <th>V157</th>\n",
       "      <th>V158</th>\n",
       "      <th>V159</th>\n",
       "      <th>V160</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.033125</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.018034</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.013706</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082207</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.013473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115161</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22016</th>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.018792</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033956</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22017</th>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.002438</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034481</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22018</th>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.021311</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.034076</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22019</th>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.064734</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027758</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22020</th>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.008917</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010225</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22021 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0      0.000946  0.004229  0.001029  0.002597  0.001067  0.001159  0.001489   \n",
       "1      0.000601  0.002419  0.001877  0.013706  0.000828  0.004858  0.000815   \n",
       "2      0.000274  0.001343  0.000217  0.001005  0.000304  0.000291  0.000513   \n",
       "3      0.000574  0.006220  0.000623  0.001124  0.000791  0.000435  0.001030   \n",
       "4      0.002103  0.006105  0.001893  0.001594  0.001879  0.001030  0.005828   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "22016  0.000609  0.002622  0.000624  0.018792  0.000762  0.000707  0.000686   \n",
       "22017  0.001277  0.007287  0.003990  0.001820  0.002148  0.001136  0.002438   \n",
       "22018  0.002292  0.004106  0.021311  0.001558  0.001766  0.000485  0.002597   \n",
       "22019  0.001918  0.005234  0.002407  0.064734  0.004365  0.001380  0.002878   \n",
       "22020  0.000851  0.003010  0.001833  0.008917  0.001172  0.000779  0.001236   \n",
       "\n",
       "             V8        V9       V10  ...      V151      V152      V153  \\\n",
       "0      0.001309  0.033125  0.002814  ...  0.021782  0.001329  0.001360   \n",
       "1      0.001497  0.001721  0.001383  ...  0.005984  0.000314  0.001147   \n",
       "2      0.000618  0.018509  0.001293  ...  0.006437  0.000406  0.000828   \n",
       "3      0.001222  0.003205  0.005092  ...  0.082207  0.001164  0.001214   \n",
       "4      0.001948  0.003762  0.013473  ...  0.115161  0.002071  0.002566   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "22016  0.000967  0.005292  0.002555  ...  0.033956  0.000439  0.000826   \n",
       "22017  0.002418  0.000971  0.003876  ...  0.034481  0.001132  0.001727   \n",
       "22018  0.002586  0.000700  0.006279  ...  0.016436  0.000289  0.002211   \n",
       "22019  0.001677  0.003644  0.003618  ...  0.027758  0.000506  0.002391   \n",
       "22020  0.001382  0.001119  0.001367  ...  0.010225  0.000480  0.001719   \n",
       "\n",
       "           V154      V156      V157      V158      V159      V160  sentiment  \n",
       "0      0.000579  0.002206  0.000220  0.018034  0.001644  0.001930          0  \n",
       "1      0.000138  0.000627  0.000383  0.002241  0.000308  0.001134          1  \n",
       "2      0.000313  0.002502  0.000056  0.001123  0.005047  0.000774          0  \n",
       "3      0.000259  0.002931  0.000724  0.000880  0.001221  0.001472          0  \n",
       "4      0.000289  0.001988  0.000751  0.002018  0.001873  0.002254          0  \n",
       "...         ...       ...       ...       ...       ...       ...        ...  \n",
       "22016  0.000386  0.001724  0.000448  0.001086  0.000960  0.001230          0  \n",
       "22017  0.000334  0.000915  0.000909  0.000770  0.002556  0.002130          0  \n",
       "22018  0.000497  0.034076  0.000394  0.001061  0.003629  0.001872          0  \n",
       "22019  0.001036  0.001988  0.000870  0.002659  0.032034  0.002224          0  \n",
       "22020  0.000256  0.001047  0.000749  0.000945  0.001902  0.001521          1  \n",
       "\n",
       "[22021 rows x 151 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_STM_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Bert_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizing the bag of words\n",
    "vectorizer_model = CountVectorizer(min_df = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the columns in X and y\n",
    "bow_X = vectorizer_model.fit_transform(df[\"review_text\"].values)\n",
    "bow_y = df[\"review_score\"].values\n",
    "STM_X = df_STM.drop(\"sentiment\", axis=1)\n",
    "STM_X = STM_X.values\n",
    "STM_y = df_STM[\"sentiment\"].values\n",
    "STM_X_selected = df_STM_selected.drop(\"sentiment\", axis = 1)\n",
    "STM_y_selected = df_STM_selected[\"sentiment\"].values\n",
    "Bert_X = df_Bert.drop([\"sentiment\", \"Unnamed: 0\"], axis=1)\n",
    "Bert_X = Bert_X.values\n",
    "Bert_y = df_Bert[\"sentiment\"].values\n",
    "Bert_X_selected = df_Bert_selected.drop(\"sentiment\", axis = 1)\n",
    "Bert_y_selected = df_Bert_selected[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22024x13981 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1828966 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the sets\n",
    "bow_X_train, bow_X_test, bow_y_train, bow_y_test = train_test_split(bow_X, bow_y, random_state = 101)\n",
    "STM_X_train, STM_X_test, STM_y_train, STM_y_test = train_test_split(STM_X, STM_y, random_state = 101)\n",
    "Bert_X_train, Bert_X_test, Bert_y_train, Bert_y_test = train_test_split(Bert_X, Bert_y, random_state = 101)\n",
    "STM_X_selected_train, STM_X_selected_test, STM_y_selected_train, STM_y_selected_test = train_test_split(STM_X_selected,STM_y_selected, random_state=101)\n",
    "Bert_X_selected_train, Bert_X_selected_test, Bert_y_selected_train, Bert_y_selected_test = train_test_split(Bert_X_selected,Bert_y_selected, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_bow = preprocessing.LabelEncoder()\n",
    "bow_y_train = le_bow.fit_transform(bow_y_train)\n",
    "bow_y_test = le_bow.transform(bow_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_stm = preprocessing.LabelEncoder()\n",
    "STM_y_train = le_stm.fit_transform(STM_y_train)\n",
    "STM_y_test = le_stm.transform(STM_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_bert = preprocessing.LabelEncoder()\n",
    "Bert_y_train = le_bert.fit_transform(Bert_y_train)\n",
    "Bert_y_test = le_bert.transform(Bert_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_stm_selected = preprocessing.LabelEncoder()\n",
    "STM_y_selected_train = le_stm.fit_transform(STM_y_selected_train)\n",
    "STM_y_selected_test = le_stm.transform(STM_y_selected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_bert_selected = preprocessing.LabelEncoder()\n",
    "Bert_y_selected_train = le_bert.fit_transform(Bert_y_selected_train)\n",
    "Bert_y_selected_test = le_bert.transform(Bert_y_selected_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state=101, max_iter=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_LR = {\"C\": np.logspace(-4, 4, 20), \"class_weight\":[None, \"balanced\"], \"solver\": [\"liblinear\", \"lbfgs\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n LogisticRegression(C=0.23357214690901212, class_weight='balanced',\n",
      "                   max_iter=1000, random_state=101, solver='liblinear')\n",
      "\\n The best score across ALL searched params:\\n 0.6998293663767401\n",
      "\\n The best parameters across ALL searched params:\\n {'solver': 'liblinear', 'class_weight': 'balanced', 'C': 0.23357214690901212}\n"
     ]
    }
   ],
   "source": [
    "#BOW\n",
    "Randomized_search_LR_BOW = RandomizedSearchCV(LR, parameters_LR, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_LR_BOW.fit(bow_X_train, bow_y_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_LR_BOW.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_LR_BOW.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_LR_BOW.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7110347788750535"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BOW final\n",
    "LR_final_BOW = Randomized_search_LR_BOW.best_estimator_\n",
    "LR_final_BOW.fit(bow_X_train, bow_y_train)\n",
    "bow_y_pred_LR = LR_final_BOW.predict(bow_X_test)\n",
    "#test score\n",
    "f1_score(bow_y_test, bow_y_pred_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n LogisticRegression(C=78.47599703514607, class_weight='balanced', max_iter=1000,\n",
      "                   random_state=101)\n",
      "\\n The best score across ALL searched params:\\n 0.6349198631141159\n",
      "\\n The best parameters across ALL searched params:\\n {'solver': 'lbfgs', 'class_weight': 'balanced', 'C': 78.47599703514607}\n"
     ]
    }
   ],
   "source": [
    "#STM\n",
    "Randomized_search_LR_STM = RandomizedSearchCV(LR, parameters_LR, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_LR_STM.fit(STM_X_train, STM_y_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_LR_STM.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_LR_STM.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_LR_STM.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6470588235294117"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STM final\n",
    "LR_final_STM = Randomized_search_LR_STM.best_estimator_\n",
    "LR_final_STM.fit(STM_X_train, STM_y_train)\n",
    "STM_y_pred_LR = LR_final_STM.predict(STM_X_test)\n",
    "#test score\n",
    "f1_score(STM_y_test, STM_y_pred_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n LogisticRegression(C=78.47599703514607, class_weight='balanced', max_iter=1000,\n",
      "                   random_state=101)\n",
      "\\n The best score across ALL searched params:\\n 0.634387842420699\n",
      "\\n The best parameters across ALL searched params:\\n {'solver': 'lbfgs', 'class_weight': 'balanced', 'C': 78.47599703514607}\n"
     ]
    }
   ],
   "source": [
    "#STM selected\n",
    "Randomized_search_LR_STM_selected = RandomizedSearchCV(LR, parameters_LR, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_LR_STM_selected.fit(STM_X_selected_train, STM_y_selected_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_LR_STM_selected.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_LR_STM_selected.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_LR_STM_selected.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6472564389697649"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STM selected final\n",
    "LR_final_STM_selected = Randomized_search_LR_STM_selected.best_estimator_\n",
    "LR_final_STM_selected.fit(STM_X_selected_train, STM_y_selected_train)\n",
    "STM_y_selected_pred_LR = LR_final_STM_selected.predict(STM_X_selected_test)\n",
    "#test score\n",
    "f1_score(STM_y_selected_test, STM_y_selected_pred_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n LogisticRegression(C=1.623776739188721, class_weight='balanced', max_iter=1000,\n",
      "                   random_state=101, solver='liblinear')\n",
      "\\n The best score across ALL searched params:\\n 0.4174763120942407\n",
      "\\n The best parameters across ALL searched params:\\n {'solver': 'liblinear', 'class_weight': 'balanced', 'C': 1.623776739188721}\n"
     ]
    }
   ],
   "source": [
    "#BERTopic\n",
    "Randomized_search_LR_Bert = RandomizedSearchCV(LR, parameters_LR, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_LR_Bert.fit(Bert_X_train, Bert_y_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_LR_Bert.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_LR_Bert.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_LR_Bert.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.433465560764515"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BERT final 0.48 veel features, 0.42 outlier reduction\n",
    "LR_final_Bert = Randomized_search_LR_Bert.best_estimator_\n",
    "LR_final_Bert.fit(Bert_X_train, Bert_y_train)\n",
    "Bert_y_pred_LR = LR_final_Bert.predict(Bert_X_test)\n",
    "#test score\n",
    "f1_score(Bert_y_test, Bert_y_pred_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n LogisticRegression(C=206.913808111479, class_weight='balanced', max_iter=1000,\n",
      "                   random_state=101)\n",
      "\\n The best score across ALL searched params:\\n 0.4135250077924589\n",
      "\\n The best parameters across ALL searched params:\\n {'solver': 'lbfgs', 'class_weight': 'balanced', 'C': 206.913808111479}\n"
     ]
    }
   ],
   "source": [
    "#Bertopic selected\n",
    "Randomized_search_LR_Bert_selected = RandomizedSearchCV(LR, parameters_LR, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_LR_Bert_selected.fit(Bert_X_selected_train, Bert_y_selected_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_LR_Bert_selected.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_LR_Bert_selected.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_LR_Bert_selected.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42845594179466445"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bertopic selected final\n",
    "LR_final_Bert_selected = Randomized_search_LR_Bert_selected.best_estimator_\n",
    "LR_final_Bert_selected.fit(Bert_X_selected_train, Bert_y_selected_train)\n",
    "Bert_y_selected_pred_LR = LR_final_Bert_selected.predict(Bert_X_selected_test)\n",
    "#test score\n",
    "f1_score(Bert_y_selected_test, Bert_y_selected_pred_LR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Support vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = LinearSVC(random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_SVM = {\"C\": np.logspace(-4, 4, 20), \"class_weight\":[None, \"balanced\"], \"loss\": [\"hinge\", \"squared_hinge\"]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n LinearSVC(C=0.03359818286283781, class_weight='balanced', loss='hinge',\n",
      "          random_state=101)\n",
      "\\n The best score across ALL searched params:\\n 0.6928925266833614\n",
      "\\n The best parameters across ALL searched params:\\n {'loss': 'hinge', 'class_weight': 'balanced', 'C': 0.03359818286283781}\n"
     ]
    }
   ],
   "source": [
    "#BOW\n",
    "Randomized_search_SVM_BOW = RandomizedSearchCV(SVM, parameters_SVM, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_SVM_BOW.fit(bow_X_train, bow_y_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_SVM_BOW.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_SVM_BOW.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_SVM_BOW.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7030201342281879"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BOW final\n",
    "SVM_final_BOW = Randomized_search_SVM_BOW.best_estimator_\n",
    "SVM_final_BOW.fit(bow_X_train, bow_y_train)\n",
    "bow_y_pred_SVM = SVM_final_BOW.predict(bow_X_test)\n",
    "#test score\n",
    "f1_score(bow_y_test, bow_y_pred_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n LinearSVC(C=0.615848211066026, class_weight='balanced', random_state=101)\n",
      "\\n The best score across ALL searched params:\\n 0.6352700929235662\n",
      "\\n The best parameters across ALL searched params:\\n {'loss': 'squared_hinge', 'class_weight': 'balanced', 'C': 0.615848211066026}\n"
     ]
    }
   ],
   "source": [
    "#STM\n",
    "Randomized_search_SVM_STM = RandomizedSearchCV(SVM, parameters_SVM, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_SVM_STM.fit(STM_X_train, STM_y_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_SVM_STM.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_SVM_STM.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_SVM_STM.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6394913986537024"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STM final\n",
    "SVM_final_STM = Randomized_search_SVM_STM.best_estimator_\n",
    "SVM_final_STM.fit(STM_X_train, STM_y_train)\n",
    "STM_y_pred_SVM = SVM_final_STM.predict(STM_X_test)\n",
    "#test score\n",
    "f1_score(STM_y_test, STM_y_pred_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVM3 = LinearSVC(C=0.615848211066026, class_weight='balanced', random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6394913986537024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88      4422\n",
      "           1       0.54      0.79      0.64      1084\n",
      "\n",
      "    accuracy                           0.82      5506\n",
      "   macro avg       0.74      0.81      0.76      5506\n",
      "weighted avg       0.86      0.82      0.84      5506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LSVM3.fit(STM_X_train, STM_y_train)\n",
    "STM_y_pred_SVM_cm = LSVM3.predict(STM_X_test)\n",
    "#test score\n",
    "print(f1_score(STM_y_test, STM_y_pred_SVM_cm))\n",
    "print(classification_report(STM_y_test, STM_y_pred_SVM_cm))\n",
    "cm2 = confusion_matrix(STM_y_test, STM_y_pred_SVM_cm, labels=[1,0], normalize=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x20878e3e460>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp_LSVM3 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=[\"Negative sentiment\", \"Positive sentiment\"])\n",
    "disp_LSVM3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n LinearSVC(C=206.913808111479, class_weight='balanced', loss='hinge',\n",
      "          random_state=101)\n",
      "\\n The best score across ALL searched params:\\n 0.6354052662562726\n",
      "\\n The best parameters across ALL searched params:\\n {'loss': 'hinge', 'class_weight': 'balanced', 'C': 206.913808111479}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#STM selected\n",
    "Randomized_search_SVM_STM_selected = RandomizedSearchCV(SVM, parameters_SVM, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_SVM_STM_selected.fit(STM_X_selected_train, STM_y_selected_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_SVM_STM_selected.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_SVM_STM_selected.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_SVM_STM_selected.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6444859813084112"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STM selected final\n",
    "SVM_final_STM_selected = Randomized_search_SVM_STM_selected.best_estimator_\n",
    "SVM_final_STM_selected.fit(STM_X_selected_train, STM_y_selected_train)\n",
    "STM_y_selected_pred_SVM = SVM_final_STM_selected.predict(STM_X_selected_test)\n",
    "#test score\n",
    "f1_score(STM_y_selected_test, STM_y_selected_pred_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n LinearSVC(C=0.615848211066026, class_weight='balanced', random_state=101)\n",
      "\\n The best score across ALL searched params:\\n 0.41992654094857007\n",
      "\\n The best parameters across ALL searched params:\\n {'loss': 'squared_hinge', 'class_weight': 'balanced', 'C': 0.615848211066026}\n"
     ]
    }
   ],
   "source": [
    "#BERTopic\n",
    "Randomized_search_SVM_Bert = RandomizedSearchCV(SVM, parameters_SVM, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_SVM_Bert.fit(Bert_X_train, Bert_y_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_SVM_Bert.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_SVM_Bert.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_SVM_Bert.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4271523178807948"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BERT final 0.47, 0.42 reduction\n",
    "SVM_final_Bert = Randomized_search_SVM_Bert.best_estimator_\n",
    "SVM_final_Bert.fit(Bert_X_train, Bert_y_train)\n",
    "Bert_y_pred_SVM = SVM_final_Bert.predict(Bert_X_test)\n",
    "#test score\n",
    "f1_score(Bert_y_test, Bert_y_pred_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVM2 = LinearSVC(C=0.615848211066026, class_weight='balanced', random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4271523178807948\n"
     ]
    }
   ],
   "source": [
    "LSVM2.fit(Bert_X_train, Bert_y_train)\n",
    "Bert_y_pred_SVM_cm = LSVM2.predict(Bert_X_test)\n",
    "#test score\n",
    "print(f1_score(Bert_y_test, Bert_y_pred_SVM_cm))\n",
    "cm = confusion_matrix(Bert_y_test, Bert_y_pred_SVM_cm)\n",
    "cm_norm = confusion_matrix(Bert_y_test, Bert_y_pred_SVM_cm, labels=[1,0], normalize=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x208784c18e0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp_LSVM = ConfusionMatrixDisplay(confusion_matrix=cm_norm, display_labels=[\"Negative sentiment\", \"Positive sentiment\"])\n",
    "disp_LSVM.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n LinearSVC(C=0.615848211066026, class_weight='balanced', random_state=101)\n",
      "\\n The best score across ALL searched params:\\n 0.4045076545040772\n",
      "\\n The best parameters across ALL searched params:\\n {'loss': 'squared_hinge', 'class_weight': 'balanced', 'C': 0.615848211066026}\n"
     ]
    }
   ],
   "source": [
    "#Bertopic selected\n",
    "Randomized_search_SVM_Bert_selected = RandomizedSearchCV(SVM, parameters_SVM, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_SVM_Bert_selected.fit(Bert_X_selected_train, Bert_y_selected_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_SVM_Bert_selected.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_SVM_Bert_selected.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_SVM_Bert_selected.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4146341463414634"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bertopic selected final\n",
    "SVM_final_Bert_selected = Randomized_search_SVM_Bert_selected.best_estimator_\n",
    "SVM_final_Bert_selected.fit(Bert_X_selected_train, Bert_y_selected_train)\n",
    "Bert_y_selected_pred_SVM = SVM_final_Bert_selected.predict(Bert_X_selected_test)\n",
    "#test score\n",
    "f1_score(Bert_y_selected_test, Bert_y_selected_pred_SVM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(verbosity = 1, seed = 101, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters_XGB = {\"colsample_bytree:\": np.arange(0.5,1,0.1) ,\"min_child_weight\": np.arange(1,10,1), \"eta\": np.arange(0.01,0.3,0.05), \"gamma\": np.arange(0,5,1), \"max_depth\": np.arange(3,10,1), \"subsample\": np.arange(0.5,1,0.1), \"scale_pos_weight\": [1, 4.045069258], \"objective\": [\"binary:logistic\", \"binary:logitraw\", \"binary:hinge\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[12:31:30] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"colsample_bytree:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:31:31] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1,\n",
      "              colsample_bytree:=0.8999999999999999, enable_categorical=False,\n",
      "              eta=0.21000000000000002, gamma=1, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.209999993,\n",
      "              max_delta_step=0, max_depth=9, min_child_weight=9, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=101,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=4.045069258, seed=101,\n",
      "              subsample=0.7999999999999999, tree_method='exact',\n",
      "              use_label_encoder=False, ...)\n",
      "\\n The best score across ALL searched params:\\n 0.6497010438331758\n",
      "\\n The best parameters across ALL searched params:\\n {'subsample': 0.7999999999999999, 'scale_pos_weight': 4.045069258, 'objective': 'binary:logistic', 'min_child_weight': 9, 'max_depth': 9, 'gamma': 1, 'eta': 0.21000000000000002, 'colsample_bytree:': 0.8999999999999999}\n"
     ]
    }
   ],
   "source": [
    "#BOW\n",
    "Randomized_search_XGB = RandomizedSearchCV(XGB, parameters_XGB, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_XGB.fit(bow_X_train, bow_y_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_XGB.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_XGB.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_XGB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:31:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"colsample_bytree:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:31:48] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6516853932584269"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BOW final\n",
    "XGB_final_BOW = Randomized_search_XGB.best_estimator_\n",
    "XGB_final_BOW.fit(bow_X_train, bow_y_train)\n",
    "bow_y_pred_XGB = XGB_final_BOW.predict(bow_X_test)\n",
    "#test score\n",
    "f1_score(bow_y_test, bow_y_pred_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[12:40:27] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"colsample_bytree:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:40:28] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, colsample_bytree:=0.6,\n",
      "              enable_categorical=False, eta=0.21000000000000002, gamma=2,\n",
      "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.209999993, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=6, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=12, num_parallel_tree=1,\n",
      "              predictor='auto', random_state=101, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=4.045069258, seed=101,\n",
      "              subsample=0.8999999999999999, tree_method='exact',\n",
      "              use_label_encoder=False, ...)\n",
      "\\n The best score across ALL searched params:\\n 0.6528368792586672\n",
      "\\n The best parameters across ALL searched params:\\n {'subsample': 0.8999999999999999, 'scale_pos_weight': 4.045069258, 'objective': 'binary:logistic', 'min_child_weight': 6, 'max_depth': 6, 'gamma': 2, 'eta': 0.21000000000000002, 'colsample_bytree:': 0.6}\n"
     ]
    }
   ],
   "source": [
    "#STM\n",
    "Randomized_search_XGB_STM = RandomizedSearchCV(XGB, parameters_XGB, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_XGB_STM.fit(STM_X_train, STM_y_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_XGB_STM.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_XGB_STM.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_XGB_STM.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:40:44] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"colsample_bytree:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:40:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6522476675148431"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STM final\n",
    "XGB_final_STM = Randomized_search_XGB_STM.best_estimator_\n",
    "XGB_final_STM.fit(STM_X_train, STM_y_train)\n",
    "XGB_y_pred_STM = XGB_final_STM.predict(STM_X_test)\n",
    "#test score\n",
    "f1_score(STM_y_test, XGB_y_pred_STM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:47:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"colsample_bytree:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:47:39] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.4.0, the default evaluation metric used with the objective 'binary:logitraw' was changed from 'auc' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1,\n",
      "              colsample_bytree:=0.8999999999999999, enable_categorical=False,\n",
      "              eta=0.060000000000000005, gamma=3, gpu_id=-1,\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.0599999987, max_delta_step=0, max_depth=4,\n",
      "              min_child_weight=4, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=12, num_parallel_tree=1,\n",
      "              objective='binary:logitraw', predictor='auto', random_state=101,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=4.045069258, seed=101,\n",
      "              subsample=0.5, tree_method='exact', ...)\n",
      "\\n The best score across ALL searched params:\\n 0.6486305624129585\n",
      "\\n The best parameters across ALL searched params:\\n {'subsample': 0.5, 'scale_pos_weight': 4.045069258, 'objective': 'binary:logitraw', 'min_child_weight': 4, 'max_depth': 4, 'gamma': 3, 'eta': 0.060000000000000005, 'colsample_bytree:': 0.8999999999999999}\n"
     ]
    }
   ],
   "source": [
    "#STM selected\n",
    "Randomized_search_XGB_STM_selected = RandomizedSearchCV(XGB, parameters_XGB, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_XGB_STM_selected.fit(STM_X_selected_train, STM_y_selected_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_XGB_STM_selected.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_XGB_STM_selected.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_XGB_STM_selected.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:47:52] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"colsample_bytree:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:47:52] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.4.0, the default evaluation metric used with the objective 'binary:logitraw' was changed from 'auc' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6528013582342953"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STM selected final\n",
    "XGB_final_STM_selected = Randomized_search_XGB_STM_selected.best_estimator_\n",
    "XGB_final_STM_selected.fit(STM_X_selected_train, STM_y_selected_train)\n",
    "STM_y_selected_pred_XGB = XGB_final_STM_selected.predict(STM_X_selected_test)\n",
    "#test score\n",
    "f1_score(STM_y_selected_test, STM_y_selected_pred_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[12:52:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"colsample_bytree:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:52:46] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.4.0, the default evaluation metric used with the objective 'binary:logitraw' was changed from 'auc' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, colsample_bytree:=0.6,\n",
      "              enable_categorical=False, eta=0.11, gamma=1, gpu_id=-1,\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.109999999, max_delta_step=0, max_depth=7,\n",
      "              min_child_weight=8, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=12, num_parallel_tree=1,\n",
      "              objective='binary:logitraw', predictor='auto', random_state=101,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=4.045069258, seed=101,\n",
      "              subsample=0.7999999999999999, tree_method='exact', ...)\n",
      "\\n The best score across ALL searched params:\\n 0.41412158416101114\n",
      "\\n The best parameters across ALL searched params:\\n {'subsample': 0.7999999999999999, 'scale_pos_weight': 4.045069258, 'objective': 'binary:logitraw', 'min_child_weight': 8, 'max_depth': 7, 'gamma': 1, 'eta': 0.11, 'colsample_bytree:': 0.6}\n"
     ]
    }
   ],
   "source": [
    "#BERTopic\n",
    "Randomized_search_XGB_Bert = RandomizedSearchCV(XGB, parameters_XGB, verbose=2, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_XGB_Bert.fit(Bert_X_train, Bert_y_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_XGB_Bert.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_XGB_Bert.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_XGB_Bert.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:53:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"colsample_bytree:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:53:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.4.0, the default evaluation metric used with the objective 'binary:logitraw' was changed from 'auc' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42906976744186054"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BERT final\n",
    "XGB_final_Bert = Randomized_search_XGB_Bert.best_estimator_\n",
    "XGB_final_Bert.fit(Bert_X_train, Bert_y_train)\n",
    "Bert_y_pred_XGB = XGB_final_Bert.predict(Bert_X_test)\n",
    "#test score\n",
    "f1_score(Bert_y_test, Bert_y_pred_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\anaconda3\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:57:59] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"colsample_bytree:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:57:59] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Results from Randomized Search \n",
      "\\n The best estimator across ALL searched params:\\n XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, colsample_bytree:=0.5,\n",
      "              enable_categorical=False, eta=0.26, gamma=3, gpu_id=-1,\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.25999999, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=12, num_parallel_tree=1,\n",
      "              predictor='auto', random_state=101, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=4.045069258, seed=101,\n",
      "              subsample=0.8999999999999999, tree_method='exact',\n",
      "              use_label_encoder=False, ...)\n",
      "\\n The best score across ALL searched params:\\n 0.43812266457694093\n",
      "\\n The best parameters across ALL searched params:\\n {'subsample': 0.8999999999999999, 'scale_pos_weight': 4.045069258, 'objective': 'binary:logistic', 'min_child_weight': 1, 'max_depth': 3, 'gamma': 3, 'eta': 0.26, 'colsample_bytree:': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#Bertopic selected\n",
    "Randomized_search_XGB_Bert_selected = RandomizedSearchCV(XGB, parameters_XGB, verbose=1, scoring=\"f1\", n_jobs = 2)\n",
    "Randomized_search_XGB_Bert_selected.fit(Bert_X_selected_train, Bert_y_selected_train)\n",
    "print(\" Results from Randomized Search \" )\n",
    "print(\"\\\\n The best estimator across ALL searched params:\\\\n\",Randomized_search_XGB_Bert_selected.best_estimator_)\n",
    "print(\"\\\\n The best score across ALL searched params:\\\\n\",Randomized_search_XGB_Bert_selected.best_score_)\n",
    "print(\"\\\\n The best parameters across ALL searched params:\\\\n\",Randomized_search_XGB_Bert_selected.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:58:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"colsample_bytree:\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:58:11] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45103092783505155"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bertopic selected final\n",
    "XGB_final_Bert_selected = Randomized_search_XGB_Bert_selected.best_estimator_\n",
    "XGB_final_Bert_selected.fit(Bert_X_selected_train, Bert_y_selected_train)\n",
    "Bert_y_selected_pred_XGB = XGB_final_Bert_selected.predict(Bert_X_selected_test)\n",
    "#test score\n",
    "f1_score(Bert_y_selected_test, Bert_y_selected_pred_XGB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
